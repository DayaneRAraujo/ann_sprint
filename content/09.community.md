# Community Engagement
## How can we motivate researchers to annotate content?

- _Award a stamp/reward/badge for annotations_: here, it is important to acknowledge the challenge that incentivising a behaviour is difficult if it is not yet rewarded more systematically within the research ecosystem (e.g. for example via grants). Assigning a DOI or a badge
- _Start small_: annotate smaller components of the research article such as the title or the abstract
- _Gamification_: make it fun! See an example from a previous eLife Sprint, [appstract](https://appstract.pub/). 
- _Embed annotations in the publishing process_: make use of existing “check points” in the publishing system to encourage researchers to annotate their research articles/abstracts (e.g. publishers could ask researchers to annotate their abstract when they submit their paper, similar to assigning keywords). We reached out to members of the eLife community for feedback on this 

## Citable annotations? 

We discussed further the idea of how to acknowledge the work of curators in a specific channel of the hackathon called “product clinic”, created to help projects to identify core value propositions, audience, user stories and more. Here is a partial summarized transcript of the thread we had to discuss citable annotations. Note: the conversations were adapted by T.L. for clarity and anonymity, in good faith to preserve the conversation, but respecting the privacy of people involved:  

- Team member A: 

At #team-annotate we are working on possible incentives for researchers to annotate their articles. One of the options we discussed is the possibility of giving an identifier (like. a DOI) to these kind of contributions and even make them citable. Do you know if it is possible to do so for this kind of work/contribution?

- eLife Sprint staff A: 

I don’t believe there are any restrictions that would prevent using a DOI. According to the DOI.org faq, a DOI can be assigned to “any entity — physical, digital or abstract — that you wish to identify, primarily for sharing with an interested user community or managing as intellectual property.”

A DOI in and of itself is not generally perceived as such unless linked to a higher level incentive such as, say, recognition of the content the DOI represents for the purposes of funding or career progression

- Team member A: 

After discussing it with the team members, we thought that maybe a badge/stamp system instead would be bette -it may also be more "visual" than a DOI. But it's good to know we can consider DOIs too. 

- eLife Sprint staff B: 

If annotations, as a web standard, already have URIs, would mean that adding a DOI is duplicative. Nevertheless, DOIs are only really valuable as scholarly currency if some funder or tenure committee recognizes the thing the DOI is attached to. Badges seem like a good way to go. 
This seems like a good resource: [Annotation Is Now a Web Standard](https://web.hypothes.is/blog/annotation-is-now-a-web-standard/)

- eLife Sprint  staff A:

For what it’s worth, eLife funded much of the work that went into [Hypothes.is](hypothes.is) becoming a publisher-friendly option for scholarly annotation ([eLife enhances open annotation with Hypothesis to promote scientific discussion online](https://elifesciences.org/for-the-press/81d42f7d/elife-enhances-open-annotation-with-hypothesis-to-promote-scientific-discussion-online)).
As to whether that makes Hypothesis itself an actual web standard, that’s up to the definition of what a web standard is.  I think it’s fair to say that it is a solution based on principles and practices that have been approved by the W3C consortium.

Once the technical barriers to annotation on academic content were overcome however, there remain other issues that impact the usage of open annotations on academic research. They range from the lack of incentives, to reticence by researchers to publicly critique a peer’s (especially a senior peer’s) work, to fear of controversy.
Public annotations pertaining to academic papers therefore remain, at least in our experience, sadly underused.

- eLife Sprint  staff B:

The w3c has recognized the Recommendations of the Annotation Working Group. Their [architecture model](https://www.w3.org/annotation/) leads me to believe that the goal is that annotations will be anchored to URIs. 

-eLife Sprint  staff A:

You can already use the share icon on any hypothesis annotation to share it via a unique URI: https://hyp.is/-cFm4AajEeiHGMe1j9pq5g/elifesciences.org/for-the-press/81d42f7d/elife-enhances-open-annotation-with-hypothesis-to-promote-scientific-discussion-online
 

- eLife Sprint  staff A:

First thing that came to mind regarding abstract keywords is reviewer/editor matching, Daniel Ecer is the brain behind eLife’s PeerScout project, which focuses on abstract keyword extraction to help make reviewer/editor matching easier ([see this this talk](https://www.youtube.com/watch?v=htkCDiGbpt8))
So, it is perhaps in publishers’ favour to get researchers to annotate their abstracts, but what does researchers gain from annotating correctly? Moreover, what is correctly? 
 
Ultimately the reviewer/editor has the power to decide whether or not to review, so whatever they think is correct, is currently considered “correct”. In a future where we open up peer review to all researchers, it would be beneficial to annotate your abstracts to get the appropriate reviewers to review your paper.
 
Also pointing out another open-source effort to annotate figures - the [SmartFigures Lab](http://smartfigures.net/), a part of the EMBO initiative SourceData [@doi:10.1038/nmeth.4471]
 

